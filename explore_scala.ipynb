{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data exploration (Scala)\n",
    "\n",
    "This notebook contains some data exploration in scala.  It assumes you've already run the ETL process (see README or etl notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@24d30bd6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// just like with pyspark notebook, we get a spark context for free\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s = org.apache.spark.sql.SparkSession@24d30bd6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@24d30bd6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// really useful imports\n",
    "val s = spark\n",
    "import s.implicits._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df = [attachments: array<struct<actions:array<struct<confirm:struct<dismiss_text:string,ok_text:string,text:string,title:string>,id:string,name:string,style:string,text:string,type:string,value:string>>,audio_html:string,audio_html_height:bigint,audio_html_width:bigint,author_icon:string,author_id:string,author_link:string,author_name:string,author_subname:string,callback_id:string,channel_id:string,channel_name:string,color:string,fallback:string,fields:array<struct<short:boolean,title:string,value:string>>,files:array<struct<created:bigint,deanimate_gif:string,display_as_bot:boolean,editable:boolean,external_type:string,filetype:string,id:string,image_exif_rotation:bigint,is_external:boolean,is_public:boolean,is_starred:boolean,mimetype:string,mode:stri...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[attachments: array<struct<actions:array<struct<confirm:struct<dismiss_text:string,ok_text:string,text:string,title:string>,id:string,name:string,style:string,text:string,type:string,value:string>>,audio_html:string,audio_html_height:bigint,audio_html_width:bigint,author_icon:string,author_id:string,author_link:string,author_name:string,author_subname:string,callback_id:string,channel_id:string,channel_name:string,color:string,fallback:string,fields:array<struct<short:boolean,title:string,value:string>>,files:array<struct<created:bigint,deanimate_gif:string,display_as_bot:boolean,editable:boolean,external_type:string,filetype:string,id:string,image_exif_rotation:bigint,is_external:boolean,is_public:boolean,is_starred:boolean,mimetype:string,mode:stri..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// reading a dataframe looks basically identical to pyspark\n",
    "val df = s.read.parquet(\"parquet_data/rocdev/events.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168340"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------+-------+-------------+-------+----+--------------+------+----+-----+------+-----+-------+--------+----+---------+------------+----+-------------+--------+--------------+-------+---------+-------+-----------+-----------+-----------------+----+-------+----+---------+-----+---+----+------+---------------+----+--------+\n",
      "|attachments|bot_id|bot_link|channel|client_msg_id|comment|date|display_as_bot|edited|file|files|hidden|icons|inviter|is_intro|item|item_type|latest_reply|name|new_broadcast|old_name|parent_user_id|purpose|reactions|replies|reply_count|reply_users|reply_users_count|root|subtype|text|thread_ts|topic| ts|type|upload|upload_reply_to|user|username|\n",
      "+-----------+------+--------+-------+-------------+-------+----+--------------+------+----+-----+------+-----+-------+--------+----+---------+------------+----+-------------+--------+--------------+-------+---------+-------+-----------+-----------+-----------------+----+-------+----+---------+-----+---+----+------+---------------+----+--------+\n",
      "+-----------+------+--------+-------+-------------+-------+----+--------------+------+----+-----+------+-----+-------+--------+----+---------+------------+----+-------------+--------+--------------+-------+---------+-------+-----------+-----------+-----------------+----+-------+----+---------+-----+---+----+------+---------------+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"ts\").isNull).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|          channel|count|\n",
      "+-----------------+-----+\n",
      "|          general|71493|\n",
      "|          careers|16418|\n",
      "|        mentoring| 9293|\n",
      "|         politics| 6754|\n",
      "|          paychex| 5639|\n",
      "|       javascript| 5158|\n",
      "|         security| 4267|\n",
      "|           gaming| 3910|\n",
      "|   remote-workers| 2839|\n",
      "|american-football| 2777|\n",
      "|           devops| 2602|\n",
      "|           python| 2440|\n",
      "|              git| 2397|\n",
      "|           random| 2362|\n",
      "|             food| 2138|\n",
      "|              www| 1897|\n",
      "|           status| 1632|\n",
      "|fakeinternetmoney| 1542|\n",
      "|   ethics-in-tech| 1496|\n",
      "|           dotnet| 1424|\n",
      "+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// group by channel and count - note again it looks almost identical to the pyspark\n",
    "df.groupBy(\"channel\").count.select(\"channel\", \"count\").orderBy(col(\"count\").desc).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "| the|75926|\n",
      "|  to|63417|\n",
      "|   a|57878|\n",
      "|   I|54112|\n",
      "| and|36504|\n",
      "|  of|33911|\n",
      "|that|30936|\n",
      "|  is|28890|\n",
      "|  in|26199|\n",
      "|  it|25950|\n",
      "| for|25096|\n",
      "| you|20649|\n",
      "|  on|16417|\n",
      "|have|16274|\n",
      "| but|15996|\n",
      "|  my|14653|\n",
      "|with|14608|\n",
      "|  be|14036|\n",
      "| was|12969|\n",
      "| not|12478|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// let's do a word count by dropping down to the rdd API, which is much easier to do in scala\n",
    "df\n",
    "    .select(\"text\")\n",
    "    .filter(col(\"text\").isNotNull)\n",
    "    .rdd\n",
    "    .flatMap(line => line.getAs[String](0).split(\" \"))\n",
    "    .filter(w => w.length > 0)\n",
    "    .map(w => (w, 1))\n",
    "    .reduceByKey(_ + _)\n",
    "    .toDF(\"word\", \"count\")\n",
    "    .orderBy(col(\"count\").desc)\n",
    "    .show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
